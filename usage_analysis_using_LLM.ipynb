{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fr5sZZ0w6R1B"
   },
   "outputs": [],
   "source": [
    "colors = [\n",
    "    \"#4b2e83\",  # Purple\n",
    "    \"#b7a57a\",  # Gold\n",
    "    \"#d9d9d6\",  # Light Gray\n",
    "    \"#5e6a71\",  # Dark Gray\n",
    "    \"#000000\",  # Black\n",
    "    \"#ffffff\",  # White\n",
    "    \"#85754d\",  # Bright Gold\n",
    "    \"#cfcfcd\"   # Cool Gray\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLEFr8mYS8Wu"
   },
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snJSYeRH2NZ-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gql import gql\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "from sqlalchemy import text\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "from system_prompt import get_prompt\n",
    "\n",
    "sys.path.append('../src') \n",
    "from connect_psql import connect_psql\n",
    "from connect_anthropic import connect_anthropic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zN88PvIS5xx0"
   },
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKb_wsgh5K5o"
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0ihnR4GiKTH"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/sample.csv')\n",
    "df['created_date'] = pd.to_datetime(df['created'], unit='ms', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove AI thinking process from AI response messages. only label the displayed responses\n",
    "df['content'] = df['content'].apply(\n",
    "        lambda x: re.search(r\"<output-cai>(.*?)</output-cai>\", x, re.DOTALL).group(1).strip() if re.search(r\"<output-cai>(.*?)</output-cai>\", x, re.DOTALL) else x\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqKLEqvg5TI0"
   },
   "source": [
    "### ANTHROPIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cEH5ZQ-GCV2N"
   },
   "outputs": [],
   "source": [
    "claude_client = connect_anthropic()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df.iloc[0:3]\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_requests = []\n",
    "for index, row in t.iterrows():\n",
    "    request = row['content']\n",
    "    custom_id = row['id']\n",
    "\n",
    "    content = get_prompt(request)\n",
    "\n",
    "    batch_requests.append({\n",
    "        \"custom_id\": custom_id,\n",
    "        \"params\": {\n",
    "            \"model\": \"claude-3-5-haiku-20241022\",\n",
    "            \"max_tokens\": 1200,\n",
    "            \"temperature\": 0,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": content.strip(),\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "    })\n",
    "\n",
    "claude_client.beta.messages.batches.create(\n",
    "    requests=batch_requests\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert IDs from previous step output\n",
    "ids = ['msgbatch_'] #edit thisline\n",
    "\n",
    "for id in ids:\n",
    "    message_batch = claude_client.beta.messages.batches.retrieve(\n",
    "        id)\n",
    "    print(message_batch.processing_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with additional headings and rationales\n",
    "\n",
    "results_data = []\n",
    "\n",
    "# Iterate through each result and extract its full structure\n",
    "for id in ids:\n",
    "    for result in claude_client.beta.messages.batches.results(id):\n",
    "        # Initialize the result entry with basic details\n",
    "        result_entry = {\n",
    "            \"custom_id\": result.custom_id,\n",
    "            \"status\": result.result.type\n",
    "        }\n",
    "\n",
    "        if result.result.type == \"succeeded\":\n",
    "            try:\n",
    "                # Extract full content as JSON from the 'text' field\n",
    "                text_content = result.result.message.content[0].text.strip()\n",
    "                # Ensure the text content contains JSON by looking for JSON delimiters\n",
    "                json_start = text_content.find(\"{\")\n",
    "                json_end = text_content.rfind(\"}\") + 1\n",
    "                \n",
    "                if json_start != -1 and json_end != 0:\n",
    "                    # Extract the JSON portion\n",
    "                    json_string = text_content[json_start:json_end]\n",
    "                    content_data = json.loads(json_string)\n",
    "                    \n",
    "                    # Populate result_entry with content details and other relevant fields\n",
    "                    result_entry.update({\n",
    "                        \"message_id\": result.result.message.id,\n",
    "                        \"model\": result.result.message.model,\n",
    "                        \"role\": result.result.message.role,\n",
    "                        \"stop_reason\": result.result.message.stop_reason,\n",
    "                        \"usage\": {\n",
    "                            \"input_tokens\": result.result.message.usage.input_tokens,\n",
    "                            \"output_tokens\": result.result.message.usage.output_tokens\n",
    "                        },\n",
    "                        \"content\": content_data  # Insert the parsed JSON content directly\n",
    "                    })\n",
    "                else:\n",
    "                    result_entry[\"error\"] = text_content\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                # Handle JSON parsing errors gracefully\n",
    "                result_entry[\"error\"] = text_content\n",
    "            except ValueError as e:\n",
    "                # Handle other content-related errors\n",
    "                result_entry[\"error\"] = str(e)\n",
    "\n",
    "        elif result.result.type == \"errored\":\n",
    "            # Capture error details for errored results\n",
    "            result_entry[\"error_type\"] = result.result.error.type\n",
    "        elif result.result.type == \"expired\":\n",
    "            # No additional data to add for expired status\n",
    "            pass\n",
    "\n",
    "        # Append each complete result entry to results_data\n",
    "        results_data.append(result_entry)\n",
    "        len(results_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Flatten a single result entry\n",
    "def flatten_result(result):\n",
    "    content = result.get('content', {})\n",
    "    ed_context = content.get('EdContext', {}) or {}\n",
    "\n",
    "    base = {\n",
    "        'custom_id': result.get('custom_id'),\n",
    "        'message_id': result.get('message_id'),\n",
    "        'model': result.get('model'),\n",
    "        'status': result.get('status'),\n",
    "        'role': result.get('role'),\n",
    "        'stop_reason': result.get('stop_reason'),\n",
    "        'input_tokens': result.get('usage', {}).get('input_tokens'),\n",
    "        'output_tokens': result.get('usage', {}).get('output_tokens'),\n",
    "        'ClarityAndSpecificity': content.get('ClarityAndSpecificity'),\n",
    "        'Subject Area': ed_context.get('Subject Area'),\n",
    "        'Grade Level': ed_context.get('Grade Level'),\n",
    "        'Pedagogical Framework': ed_context.get('Pedagogical Framework')\n",
    "    }\n",
    "\n",
    "    # These are the nested domains we want to flatten\n",
    "    domains = [\n",
    "        'Instructional Practices',\n",
    "        'Student Needs and Context',\n",
    "        'Curriculum and Content Planning',\n",
    "        'Assessment and Feedback',\n",
    "        'Professional Responsibilities',\n",
    "        'Other'\n",
    "    ]\n",
    "\n",
    "    for domain in domains:\n",
    "        subdomain_dict = content.get(domain, {})\n",
    "        if isinstance(subdomain_dict, dict):\n",
    "            for subdomain, value in subdomain_dict.items():\n",
    "                key = f\"{domain} - {subdomain}\"\n",
    "                base[key] = value\n",
    "        else:\n",
    "            # if domain exists but is not a dict, skip\n",
    "            continue\n",
    "\n",
    "    return base\n",
    "\n",
    "# Step 2: Flatten all entries\n",
    "df_flat = pd.DataFrame([flatten_result(r) for r in results_data])\n",
    "\n",
    "# Step 3: Melt to long format\n",
    "id_cols = [\n",
    "    'custom_id', 'message_id', 'model', 'status', 'role',\n",
    "    'stop_reason', 'input_tokens', 'output_tokens',\n",
    "    'ClarityAndSpecificity', 'Subject Area', 'Grade Level', 'Pedagogical Framework'\n",
    "]\n",
    "\n",
    "df_long = df_flat.melt(\n",
    "    id_vars=id_cols,\n",
    "    var_name='Category',\n",
    "    value_name='Code'\n",
    ").dropna(subset=['Code']).reset_index(drop=True)\n",
    "\n",
    "# Split 'Category' into 'Domain' and 'Subcategory'\n",
    "df_long[['domain', 'category']] = df_long['Category'].str.split(' - ', n=1, expand=True)\n",
    "\n",
    "# Rename column and drop original Category\n",
    "df_long = df_long.rename(columns={'Code': 'code_value'}).rename(columns={'custom_id': 'colleague_message_id'}).drop(columns=['Category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "flattened = []\n",
    "\n",
    "for row in results_data:\n",
    "    base = {\n",
    "        'custom_id': row.get('custom_id'),\n",
    "        'status': row.get('status'),\n",
    "        'message_id': row.get('message_id'),\n",
    "        'model': row.get('model'),\n",
    "        'role': row.get('role'),\n",
    "        'stop_reason': row.get('stop_reason'),\n",
    "        'input_tokens': row.get('usage', {}).get('input_tokens'),\n",
    "        'output_tokens': row.get('usage', {}).get('output_tokens')\n",
    "    }\n",
    "\n",
    "    parsed = False\n",
    "\n",
    "    if 'content' in row and isinstance(row['content'], dict):\n",
    "        flat_content = pd.json_normalize(row['content'], sep='_', max_level=10).to_dict(orient='records')[0]\n",
    "        base.update(flat_content)\n",
    "        flattened.append(base)\n",
    "        continue\n",
    "\n",
    "    error_text = row.get('error', '').strip()\n",
    "\n",
    "    if error_text.startswith('{'):\n",
    "        for part in error_text.split('\\n\\n'):\n",
    "            try:\n",
    "                json_obj = json.loads(part.strip())\n",
    "                base_copy = base.copy()\n",
    "                if 'content' in json_obj and isinstance(json_obj['content'], dict):\n",
    "                    flat_content = pd.json_normalize(json_obj['content'], sep='_', max_level=10).to_dict(orient='records')[0]\n",
    "                    base_copy.update(flat_content)\n",
    "                else:\n",
    "                    flat_content = pd.json_normalize(json_obj, sep='_', max_level=10).to_dict(orient='records')[0]\n",
    "                    base_copy.update(flat_content)\n",
    "                flattened.append(base_copy)\n",
    "                parsed = True\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "    if not parsed:\n",
    "        base['error'] = error_text\n",
    "        flattened.append(base)\n",
    "\n",
    "df_output = pd.DataFrame(flattened)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.columns = df_output.columns.str.replace(\"^content-\", \"\", regex=True)\n",
    "\n",
    "# Rename \"custom_id\" to \"id\"\n",
    "df_output = df_output.rename(columns={\"custom_id\": \"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## post progress LLM results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.columns[12:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean up error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output[~df_output['error'].isna()]['error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any content went to error message\n",
    "mask = df_output['error'].notna() & ~(\n",
    "    df_output['error'].str.contains('no message', na=False) | \n",
    "    df_output['error'].str.contains('no actual message', na=False)\n",
    ")\n",
    "\n",
    "df_filtered = df_output[mask]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.loc[mask, 'Other_Discourse Continuity'] = \"Modification Request\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up formatting and non eductional requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['Other_Non-Educational'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['Other_Non-Educational'] = df_output['Other_Non-Educational'].apply(\n",
    "    lambda x: 'Non-Educational' if x in [True, \"Grove's Lawn Care\"] else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['Other_Non-Educational'] = df_output['Other_Non-Educational'].apply(\n",
    "    lambda x: 'Administrative Communications' if x in ['Administrative Daily Update', 'Administrative Meeting Minutes',  'Administrative School Information', 'Graduation Speech'] else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['Other_Non-Educational'] = df_output['Other_Non-Educational'].apply(\n",
    "    lambda x: 'Modification Request' if x in ['Discourse Continuity'] else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['Other_Discourse Continuity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output['Other_Discourse Continuity'] = df_output['Other_Discourse Continuity'].apply(\n",
    "    lambda x: 'Modification Request' if x in ['Continue', 'Waiting for grade', 'Rewrite', 'Rewrite Instructions', 'Rewrite instructions', True, 'Continue', 'Proceed', 'Turn and Talks Request'] else x\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up educational labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post = df_output[['id',\n",
    "       'Instructional Practices_Differentiation and Accessibility',\n",
    "       'Instructional Practices_Explicit Teaching',\n",
    "       'Instructional Practices_Project-Based and Real-World Learning',\n",
    "       'Instructional Practices_Critical Thinking and Inquiry',\n",
    "       'Instructional Practices_Instructional Routine',\n",
    "       'Instructional Practices_Engagement and Motivation',\n",
    "       'Student Needs and Context_Classroom Setting',\n",
    "       'Student Needs and Context_Student Profiles',\n",
    "       'Student Needs and Context_Career Readiness',\n",
    "       'Curriculum and Content Planning_Planning',\n",
    "       'Curriculum and Content Planning_Tech Integration',\n",
    "       'Assessment and Feedback_Assessment',\n",
    "       'Assessment and Feedback_Feedback',\n",
    "       'Professional Responsibilities_Professional Development',\n",
    "       'Professional Responsibilities_Communication', 'Other_Non-Educational',\n",
    "       'Other_Discourse Continuity', 'Instructional Practices',\n",
    "       'Student Needs and Context', 'Curriculum and Content Planning',\n",
    "       'Professional Responsibilities', 'Other',\n",
    "       'Instructional Practices_Collaborative Learning',\n",
    "       'Assessment and Feedback',\n",
    "       'Instructional Practices_Assessment and Feedback',\n",
    "       'Instructional Practices_Assessment',\n",
    "       'Instructional Practices_Tech Integration',\n",
    "       'Instructional Practices_Assessment and Feedback_Assessment',\n",
    "       'Instructional Practices_Feedback',\n",
    "       'Curriculum and Content Planning_Assessment',\n",
    "       'Student Needs and Context_Communication',\n",
    "       'Instructional Practices_Planning',\n",
    "       'Instructional Practices_Career Readiness', 'Non-Educational',\n",
    "       'Discourse Continuity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_rename_map = {\n",
    "    'Instructional Practices_Differentiation and Accessibility': 'Differentiated Instructional Strategies',\n",
    "    'Instructional Practices_Explicit Teaching': 'Explaining Core Science Concepts',\n",
    "    'Instructional Practices_Project-Based and Real-World Learning': 'Projects',\n",
    "    'Instructional Practices_Critical Thinking and Inquiry': 'Encourage Critical Thinking and High-Level Cognition',\n",
    "    'Instructional Practices_Instructional Routine': 'Learning Progression and Routine Adjustments',\n",
    "    'Instructional Practices_Engagement and Motivation': 'Actionable Engagement Strategy',\n",
    "    'Instructional Practices_Collaborative Learning': 'Group Work',\n",
    "    'Instructional Practices_Tech Integration': 'Multimedia Use for Instruction',\n",
    "    'Instructional Practices_Assessment': 'Generate Formative Assessments',\n",
    "    \n",
    "    'Student Needs and Context_Classroom Setting': 'Homeschool',\n",
    "    'Student Needs and Context_Student Profiles': 'Special Education (IEP)',\n",
    "    'Student Needs and Context_Career Readiness': 'Student Career Exploration',\n",
    "    \n",
    "    'Curriculum and Content Planning_Planning': 'Entire Lesson Planning',\n",
    "    'Curriculum and Content Planning_Tech Integration': 'Multimedia Use for Instruction',\n",
    "    \n",
    "    'Assessment and Feedback_Assessment': 'Generate Summative Assessments',\n",
    "    'Assessment and Feedback_Feedback': 'Generate Feedback to Students',\n",
    "    \n",
    "    'Professional Responsibilities_Professional Development': 'Professional Development Needs and Requirements',\n",
    "    'Professional Responsibilities_Communication': 'Communicate with Parents or Community',\n",
    "    \n",
    "    'Other_Non-Educational': 'Non-Educational',\n",
    "    'Other_Discourse Continuity': 'Follow-Up Prompt and Continuation',\n",
    "    \n",
    "    # Clean these garbage catch-alls too\n",
    "    'Other': 'Non-Educational',\n",
    "    'Professional Responsibilities': 'Professional Development Needs and Requirements',\n",
    "    'Assessment and Feedback': 'Generate Feedback to Students',\n",
    "    'Instructional Practices': 'Explaining Core Science Concepts',\n",
    "    'Student Needs and Context': 'Social Emotional Support',\n",
    "    'Curriculum and Content Planning': 'Entire Lesson Planning',\n",
    "    'error': 'error'\n",
    "}\n",
    "\n",
    "df_output = df_output.rename(columns=column_rename_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_map = pd.read_csv('../input/qual_map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract all phrases per row, treating only strings\n",
    "df_expanded = df_post.drop(columns='id').apply(\n",
    "    lambda row: [\n",
    "        phrase.strip()\n",
    "        for val in row.dropna()\n",
    "        if isinstance(val, str)\n",
    "        for phrase in val.split(', ')\n",
    "        if phrase.strip()\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Step 2: Convert to indicator matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_indicators = pd.DataFrame(mlb.fit_transform(df_expanded), columns=mlb.classes_)\n",
    "df_indicators.insert(0, 'id', df_post['id'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize function (strip spaces and lowercase)\n",
    "normalize = lambda x: x.strip()\n",
    "\n",
    "# Create normalized sets\n",
    "valid_set = set(map(normalize, qual_map['updated_items']))\n",
    "col_set = {col for col in df_indicators.columns if col != 'id'}\n",
    "\n",
    "# Identify mismatches by original column names\n",
    "invalid_cols = [col for col in col_set if normalize(col) not in valid_set]\n",
    "\n",
    "pd.Series(invalid_cols).to_csv('../input/invalid_code.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This step requires an offline review of invalid codes and manual mapping to the existing codebook. Most invalid entries resulted from variations in naming conventions, such as “special ed,” “SPED,” “IEP,” and “special ed (IEP).” Create a new column call map_label to map the org_label to appropriate labels in the codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload the manually compiled map\n",
    "invalid_map = pd.read_csv('../input/invalid_map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in invalid_map.iterrows():\n",
    "    col1 = row['org_label']\n",
    "    col2 = row['map_label']\n",
    "    \n",
    "    if col1 in df_indicators.columns and col2 in df_indicators.columns:\n",
    "        # Merge using logical OR\n",
    "        df_indicators[col2] = df_indicators[[col1, col2]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "for _, row in invalid_map.iterrows():\n",
    "    col1 = row['org_label']\n",
    "    col2 = row['map_label']\n",
    "    \n",
    "    if col1 in df_indicators.columns and col2 in df_indicators.columns:\n",
    "        merged = df_indicators[[col1, col2]].max(axis=1)\n",
    "        \n",
    "        # Check if the merge result matches the new col2\n",
    "        if not (df_indicators[col2] == merged).all():\n",
    "            print(f\"Merge mismatch for: {col1} -> {col2}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JLEFr8mYS8Wu",
    "y0ihnR4GiKTH",
    "OG024Xmq5Vqr",
    "qfSH_ptJPpuk",
    "PAC-jhKHPw2Q",
    "lqKLEqvg5TI0",
    "6bMOIy89Onkt",
    "amkFSCdC566M",
    "DI_dWvikwv3G"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
